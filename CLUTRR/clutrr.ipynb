{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from model import LILayer_ty as LILayer\n",
    "\n",
    "import numpy as np\n",
    "from dataloader import DataCLUTRR\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataCLUTRR('data/data_db9b8f04/')\n",
    "data = dataloader.get_data('train.csv')\n",
    "def to_sparse(A):\n",
    "    st, ed = A.sum(dim=0).nonzero().T\n",
    "    edge_index = list()\n",
    "    edge_type = list()\n",
    "    for i in range(len(st)):\n",
    "        for rr in A[:,st[i],ed[i]].nonzero():\n",
    "            edge_index.append([st[i], ed[i]])\n",
    "            edge_type.append(rr[0])\n",
    "    edge_index = torch.tensor(edge_index).T\n",
    "    edge_type = torch.tensor(edge_type)\n",
    "    return edge_index, edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LILayer(20, hidden_dim=20, out_dim=20, bias=True)\n",
    "model._reset_parameters()\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|█████████████████| 89/89 [02:03<00:00,  1.39s/it, loss: 106.1521]\n",
      "Epoch: 1: 100%|██████████████████| 89/89 [01:52<00:00,  1.26s/it, loss: 15.6958]\n",
      "Epoch: 2: 100%|███████████████████| 89/89 [02:08<00:00,  1.45s/it, loss: 6.6457]\n",
      "Epoch: 3: 100%|███████████████████| 89/89 [01:53<00:00,  1.28s/it, loss: 4.1973]\n",
      "Epoch: 4:  46%|████████▊          | 41/89 [00:52<01:00,  1.27s/it, loss: 7.4972]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# loss = -torch.log(pred.softmax(dim=0)[r])\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     33\u001b[0m     sloss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     34\u001b[0m _t\u001b[39m.\u001b[39mset_postfix_str(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00msloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Supplementary-materials-for-LIGNN/CLUTRR/model.py:177\u001b[0m, in \u001b[0;36mLILayer_ty.forward.<locals>.backward_hook\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_hook\u001b[39m(grad):\n\u001b[0;32m--> 177\u001b[0m     g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver(\u001b[39mlambda\u001b[39;49;00m y: torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(f0, z0, y, retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m grad, grad,\n\u001b[1;32m    178\u001b[0m                                             max_iteration)\n\u001b[1;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m g\n",
      "File \u001b[0;32m~/Supplementary-materials-for-LIGNN/CLUTRR/model.py:127\u001b[0m, in \u001b[0;36mLILayer_ty.forward_iteration\u001b[0;34m(self, f, x0, max_iter)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[1;32m    126\u001b[0m     x \u001b[39m=\u001b[39m f0\n\u001b[0;32m--> 127\u001b[0m     f0 \u001b[39m=\u001b[39m f(x)\n\u001b[1;32m    128\u001b[0m     res\u001b[39m.\u001b[39mappend((f0 \u001b[39m-\u001b[39m x)\u001b[39m.\u001b[39mnorm()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m (\u001b[39m1e-5\u001b[39m \u001b[39m+\u001b[39m f0\u001b[39m.\u001b[39mnorm()\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m (res[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol):\n",
      "File \u001b[0;32m~/Supplementary-materials-for-LIGNN/CLUTRR/model.py:177\u001b[0m, in \u001b[0;36mLILayer_ty.forward.<locals>.backward_hook.<locals>.<lambda>\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_hook\u001b[39m(grad):\n\u001b[0;32m--> 177\u001b[0m     g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver(\u001b[39mlambda\u001b[39;00m y: torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(f0, z0, y, retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m grad, grad,\n\u001b[1;32m    178\u001b[0m                                             max_iteration)\n\u001b[1;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m g\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[1;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train sparse model\n",
    "\n",
    "N_data = 100\n",
    "\n",
    "batch_size = 400\n",
    "n_epoch = 15\n",
    "model_save = None\n",
    "\n",
    "n_split = (len(data)+batch_size-1) // batch_size\n",
    "for epoch in range(n_epoch):\n",
    "    with tqdm(range(n_split), ncols=80) as _t:\n",
    "        random.shuffle(data)\n",
    "        _t.set_description_str(f'Epoch: {epoch}')\n",
    "        ssloss = 0.0\n",
    "        for split in _t:\n",
    "            batch_st = split * batch_size\n",
    "            sloss = 0.0\n",
    "            for r, q, G in data[batch_st:batch_st+batch_size]:\n",
    "                edge_index, edge_label = to_sparse(G)\n",
    "                N = G.shape[1]\n",
    "\n",
    "                pred = model(torch.arange(N), edge_index, edge_label, N, 50, 0.7)\n",
    "                target = torch.zeros_like(G[:,0,0])\n",
    "                target[r] = 1.0\n",
    "                # target[q[0],q[1],r] = 1.0\n",
    "                # loss = F.binary_cross_entropy_with_logits(pred, target, weight, reduction='sum')\n",
    "                loss = F.cross_entropy(pred[q[0], q[1]], r*torch.ones((),dtype=torch.long))\n",
    "                if loss.item() != loss.item():\n",
    "                    raise\n",
    "                # loss = -torch.log(pred.softmax(dim=0)[r])\n",
    "\n",
    "                loss.backward()\n",
    "                sloss += loss.item()\n",
    "            _t.set_postfix_str(f'loss: {sloss:.4f}')\n",
    "            ssloss += sloss\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            model.rescale()\n",
    "            model_save = model\n",
    "        # print(ssloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 2332/2332 [00:11<00:00, 208.50it/s, 2332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2_test.csv: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 2289/2289 [00:11<00:00, 195.16it/s, 2215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3_test.csv: 0.9676714722586283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5009/5009 [00:26<00:00, 188.68it/s, 4806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4_test.csv: 0.9594729486923538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5074/5074 [00:27<00:00, 182.89it/s, 4491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5_test.csv: 0.8851005124162397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5002/5002 [00:27<00:00, 180.49it/s, 3882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6_test.csv: 0.7760895641743303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5047/5047 [00:23<00:00, 218.50it/s, 3073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7_test.csv: 0.608876560332871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5033/5033 [00:22<00:00, 225.64it/s, 2203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8_test.csv: 0.43771110669580765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5031/5031 [00:23<00:00, 215.85it/s, 1869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9_test.csv: 0.3714967203339296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 5008/5008 [00:27<00:00, 179.75it/s, 1598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10_test.csv: 0.3190894568690096\n"
     ]
    }
   ],
   "source": [
    "# test on sparse model\n",
    "\n",
    "for filename in ['1.2_test.csv','1.3_test.csv','1.4_test.csv','1.5_test.csv','1.6_test.csv',\n",
    "                 '1.7_test.csv','1.8_test.csv','1.9_test.csv','1.10_test.csv']:\n",
    "    test_data = dataloader.get_data(filename)\n",
    "    # test_data = data\n",
    "    lm = list()\n",
    "    lp = list()\n",
    "    with torch.no_grad():\n",
    "        cnt = 0\n",
    "        with tqdm(test_data, ncols=80) as _t: \n",
    "            for r, q, G in _t:\n",
    "                edge_index, edge_label = to_sparse(G)\n",
    "                N = G.shape[1]\n",
    "                pred = model(torch.arange(N), edge_index, edge_label, N, 100, 1.0)[q[0], q[1], :]\n",
    "                if pred.argmax() == r:\n",
    "                    cnt += 1\n",
    "                \n",
    "                lp.append(pred[r])\n",
    "                lm.append(pred.max())\n",
    "                _t.set_postfix_str(f'{cnt}')\n",
    "    print(f'{filename}: {cnt / len(test_data)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
